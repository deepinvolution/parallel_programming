# 1. GOAL
This assignment helps you get familiar with MPI by implementing a parallel
odd-even sort algorithm. Experimental evaluations on your implementation are
required to guide you analyze the performance and scalability of a parallel program.
You are also encouraged to explore any performance optimization and parallel
computing skills in order to receive a higher score.

# 2. Problem Description
In this assignment, you are required to implement the odd-even sort algorithm
using MPI. Odd-even sort is a comparison sort which consists of two main phases:
even-phase and odd-phase . In each phase, processes perform compare-and-swap
operations repeatedly as follows until input array is sorted.
In even-phase, all even/odd indexed pairs of adjacent elements are compared. If the
two elements of a pair are not sorted in the correct order, the two elements are
swapped. Similarly, the same compare-and-swap operation is repeated for
odd/even indexed pairs in odd-phase. The odd-even sort algorithm works by
alternating these two phases until the input array is completely sorted.

# 3. INPUT/OUTPUT FORMAT
1. Your program is required to read an unsorted array from an input file, and
generate the sorted results to another output file.
2. Your program accepts 3 input parameters separated by space. They are:
    - (Integer) the size of the array n (1 <= n <= 536870911)
    - (String) the input file name
    - (String) the output file name

    Your program will be tested by our judge system with the command below:
    ```console
    $ srun -nNPROC ./hw1 n in_file out_file
    ```
    Noted, NPROC is the number of processes, and hw1 is the name of your binary code.
3. The input file contains n 32-bit floats in binary format. The first 4 bytes
represents the first floating point number, the fifth to eighth byte represents
the second one, and so on. (Sample input files will be given by our judge
system.)
4. The output file must be generated by following the same format of the input
file. (Sample output files will also be given by our judge system.)

Note:\
The float here refers to IEEE754 binary32 , as known as single-precision
floating-point.
You can use the float type in C/C++.
Any valid float values are possible to show up in the input, except the
following values:
- -INF
- +INF
- NAN

# 4. WORKING ITEMS
1. Problem assignments: You are required to implement a parallel version of
odd-even sort under the given restrictions. Your goal is to optimize the
performance and reduce the total execution time.
    - A process can sort or perform any computations on its own local elements.
    - For the odd-even sorting phases, a process can only exchange its local
    elements with its neighbor processes according to the communication
    pattern described Section 2. For instance, MPI task with rank 5 can only
    exchange elements with MPI task with ranks 4 and 6, but not the ones with
    rank 3, 7. Noted, the neighbor relationship is not circular . For example,
    if your MPI program creates 10 processes, MPI task with rank 0 cannot
    send any message to MPI task with rank 9 during the sorting, and vise
    versa.
    - However, any communication method, including collective
    communications (i.e., broadcast, gather, scatter, etc.), are allowed for
    initialization before the sorting begins, or termination checking .
2. Requirements & Reminders:
    - Must use MPI-IO ( MPI_File* functions) to do file input and output.
    - Must follow the input/output file format and execution command line
    arguments specifications described in Section 3.
    - The implemented algorithm must follow the odd-even sort principal,
    and comply the restrictions described in Section 4.1 . If you are not
    sure whether your implementation follows the rules, please discuss with
    TA for approval.

# 5. REPORT
## Implementation
To solve this problem, I make two conventions to make things simple.
- Convention 1. For each process except last process, the number of data to be processed is always even. This avoid dealing with even or odd starting position in each phase. To meet the total number of data, we adjust last process if needed.
- Convention 2. For each process except first and last process, I always send data to previous process and receive data from next process. As a result, MPI_Sendrecv can be utilized.

The algorithm consists of two phases: even phase and odd phase:
- For even phase: Since we have convention 1, there won't be any communication between each process. We simply sort the data for each process.
- For odd phase: Each process has to send data to previous process and receive from next process except the first and last process. This is where convention 2 comes in.

After all, for each loop, we do even phase, odd phase, and judge whether to stop the loop. If each process doesn't need to sort data, we stop.

## Experiment & Analysis